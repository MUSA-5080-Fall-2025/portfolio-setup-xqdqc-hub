graffiti_count ~ neighbor_mean + local_I,
data = data_sf_grid,
family = "poisson"
)
summary(model_poisson)
model_nb <- glm.nb(
graffiti_count ~ neighbor_mean + local_I,
data = model_data
)
model_nb <- glm.nb(
graffiti_count ~ neighbor_mean + local_I,
data = data_sf_grid
)
aic_comparison <- data.frame(
Model = c("Poisson", "Negative Binomial"),
AIC = c(AIC(model_poisson), AIC(model_nb))
)
View(aic_comparison)
aic_comparison <- data.frame(
Model = c("Poisson", "Negative Binomial"),
AIC = c(AIC(model_poisson), AIC(model_nb))
)
poisson_summary <- tidy(model_poisson)
nb_summary <- tidy(model_nb)
poisson_summary <- tidy(model_poisson)
nb_summary <- tidy(model_nb)
print(poisson_summary)
print(nb_summary)
data_sf_grid <- data_sf_grid %>%
mutate(
pred_poisson = predict(model_poisson, type = "response"),
pred_nb = predict(model_nb, type = "response")
)
ggplot(data_sf_grid, aes(x = graffiti_count, y = pred_nb)) +
geom_point(alpha = 0.4) +
geom_smooth(method = "lm", color = "blue", se = FALSE) +
labs(
title = "Observed vs Predicted (Negative Binomial Model)",
x = "Observed Graffiti Count",
y = "Predicted Count"
) +
theme_minimal()
library(Metrics)
table(data_sf_grid$community_area)
cv_data <- data_sf_grid %>%
st_drop_geometry() %>%
select(community_area, graffiti_count, neighbor_mean, local_I) %>%
drop_na()
library(Metrics)
groups <- unique(data_sf_grid$community_area)
cv_results <- data.frame()
library(Metrics)
groups <- unique(data_sf_grid$community_area)
cv_results <- data.frame()
for (g in groups) {
train <- cv_data %>% filter(community_area != g)
test  <- cv_data %>% filter(community_area == g)
model_cv <- glm.nb(
graffiti_count ~ neighbor_mean + local_I,
data = train
)
preds <- predict(model_cv, newdata = test, type = "response")
mae_val <- mae(test$graffiti_count, preds)
rmse_val <- rmse(test$graffiti_count, preds)
cv_results <- rbind(cv_results, data.frame(
community_area = g,
MAE = mae_val,
RMSE = rmse_val
))
}
cv_summary <- cv_results %>%
summarise(
Mean_MAE = mean(MAE, na.rm = TRUE),
Mean_RMSE = mean(RMSE, na.rm = TRUE)
)
library(Metrics)
groups <- unique(data_sf_grid$community_area)
cv_results <- data.frame()
for (g in groups) {
train <- cv_data %>% filter(community_area != g)
test  <- cv_data %>% filter(community_area == g)
model_cv <- glm.nb(
graffiti_count ~ neighbor_mean + local_I,
data = train
)
preds <- predict(model_cv, newdata = test, type = "response")
mae_val <- mae(test$graffiti_count, preds)
rmse_val <- rmse(test$graffiti_count, preds)
cv_results <- rbind(cv_results, data.frame(
community_area = g,
MAE = mae_val,
RMSE = rmse_val
))
}
cv_summary <- cv_results %>%
summarise(
Mean_RMSE = mean(RMSE, na.rm = TRUE)
)
View(cv_results)
library(Metrics)
groups <- unique(data_sf_grid$community_area)
cv_results <- data.frame()
for (g in groups) {
train <- cv_data %>% filter(community_area != g)
test  <- cv_data %>% filter(community_area == g)
model_cv <- glm.nb(
graffiti_count ~ neighbor_mean + local_I,
data = train
)
preds <- predict(model_cv, newdata = test, type = "response")
mae_val <- mae(test$graffiti_count, preds)
rmse_val <- rmse(test$graffiti_count, preds)
cv_results <- rbind(cv_results, data.frame(
community_area = g,
MAE = mae_val,
RMSE = rmse_val
))
}
library(tidyverse)
library(Metrics)
cv_data <- data_sf_grid %>%
st_drop_geometry() %>%
select(graffiti_count, neighbor_mean, local_I, community_area) %>%
drop_na()
library(MASS)
library(dplyr)
library(sf)
data_sf_grid <- data_sf_grid %>%
mutate(community_area = as.factor(community_area))
View(data_sf_grid)
View(data_sf)
View(data_sf)
library(MASS)
library(dplyr)
library(sf)
data_sf_grid <- data_sf_grid %>%
st_join(data_sf %>% select(community_area), join = st_intersects) %>%
group_by(grid_id) %>%
summarise(
graffiti_count = first(graffiti_count),
neighbor_mean = first(neighbor_mean),
local_I = first(local_I),
hot_cold = first(hot_cold),
community_area = as.numeric(names(which.max(table(community_area))))
) %>%
ungroup()
library(Metrics)
set.seed(42)
data_sf_grid$group_id <- kmeans(st_coordinates(st_centroid(data_sf_grid)), centers = 10)$cluster
cv_results <- data.frame(group_id = character(), MAE = numeric(), RMSE = numeric())
for (g in unique(data_sf_grid$group_id)) {
train_data <- data_sf_grid[data_sf_grid$group_id != g, ]
test_data  <- data_sf_grid[data_sf_grid$group_id == g, ]
model_cv <- glm(
graffiti_count ~ neighbor_mean + local_I,
data = train_data,
family = "poisson"
)
# Predict on test data
test_data$pred <- predict(model_cv, newdata = test_data, type = "response")
# Compute errors
mae_val <- mae(test_data$graffiti_count, test_data$pred)
rmse_val <- rmse(test_data$graffiti_count, test_data$pred)
# Store results
cv_results <- rbind(cv_results, data.frame(group_id = g, MAE = mae_val, RMSE = rmse_val))
}
View(cv_results)
cv_summary <- cv_results %>%
summarise(
Mean_MAE = mean(MAE),
Mean_RMSE = mean(RMSE)
)
print(cv_summary)
ggplot(cv_results, aes(x = as.factor(group_id), y = RMSE)) +
geom_bar(stat = "identity", fill = "#3182bd") +
labs(
title = "Spatial Cross-Validation (LOGO) RMSE by Group",
x = "Spatial Group (Community Area)",
y = "RMSE"
) +
theme_minimal()
library(spatstat.geom)
# Generate predictions and residuals
data_sf_grid <- data_sf_grid %>%
mutate(
predicted = predict(model_poisson, type = "response"),
residual = graffiti_count - predicted
)
# Map observed vs predicted counts
ggplot(data_sf_grid) +
geom_sf(aes(fill = predicted), color = NA) +
scale_fill_viridis_c(option = "magma", trans = "sqrt") +
labs(
title = "Predicted Graffiti Counts (Poisson Model)",
subtitle = "City of Chicago, 500m grid",
fill = "Predicted Count"
) +
theme_minimal()
# Map residuals (model error)
ggplot(data_sf_grid) +
geom_sf(aes(fill = residual), color = NA) +
scale_fill_gradient2(
low = "#4575b4", mid = "white", high = "#d73027",
midpoint = 0
) +
labs(
title = "Model Residuals (Observed - Predicted)",
subtitle = "Blue = under-predicted, Red = over-predicted",
fill = "Residual"
) +
theme_minimal()
# Convert graffiti points to spatstat format
graffiti_ppp <- data_sf %>%
st_transform(26971) %>%   # Projected CRS for KDE
as_Spatial()
# Define window (study area)
win <- as.owin(st_union(st_geometry(data_sf_grid)))
library(spatstat.geom)
install.packages("spatstat")
library(spatstat.geom)
library(spatstat.core)
library(spatstat)
# Convert graffiti points to spatstat format
graffiti_ppp <- data_sf %>%
st_transform(26971) %>%   # Projected CRS for KDE
as_Spatial()
# Define window (study area)
win <- as.owin(st_union(st_geometry(data_sf_grid)))
# Create ppp object
graffiti_ppp <- as.ppp(graffiti_ppp, W = win)
# KDE baseline comparison (fixed version)
library(spatstat)
library(stars)
# Transform to projected CRS (in meters, for distance-based KDE)
data_sf_proj <- st_transform(data_sf, 26971)  # NAD83 / Illinois East (meters)
# Convert to spatstat ppp object
coords <- st_coordinates(data_sf_proj)
# Create observation window from study area (fishnet extent)
win <- as.owin(st_union(st_geometry(st_transform(data_sf_grid, 26971))))
# Create ppp point pattern
graffiti_ppp <- ppp(
x = coords[, 1],
y = coords[, 2],
window = win
)
# Compute KDE
graffiti_kde <- density.ppp(graffiti_ppp, sigma = 500)  # bandwidth = 500m
# Convert to data frame for ggplot
kde_df <- as.data.frame(graffiti_kde)
colnames(kde_df) <- c("x", "y", "density")
ggplot(kde_df, aes(x, y, fill = density)) +
geom_raster() +
coord_equal() +
scale_fill_viridis_c(option = "inferno") +
labs(
title = "KDE Baseline – Graffiti Removal Density",
subtitle = "Kernel Density of 311 Graffiti Removal Reports (σ = 500m)",
fill = "Density"
) +
theme_void()
# Step 1: Load and Prepare Data
library(tidyverse)
library(sf)
library(jsonlite)
library(lubridate)
# Load Graffiti Removal 311 data from Chicago Open Data API
url <- "https://data.cityofchicago.org/resource/hec5-y4x5.json?$limit=50000"
data_raw <- fromJSON(url)
# Select and clean relevant columns
data_clean <- data_raw %>%
select(service_request_number,
creation_date,
completion_date,
status,
street_address,
latitude,
longitude,
ward,
community_area) %>%
mutate(
creation_date = ymd_hms(creation_date),
completion_date = ymd_hms(completion_date),
year = year(creation_date),
month = month(creation_date, label = TRUE),
day = day(creation_date)
) %>%
drop_na(latitude, longitude)
# Convert to spatial (sf object)
data_sf <- st_as_sf(
data_clean,
coords = c("longitude", "latitude"),
crs = 4326
)
library(ggplot2)
library(sf)
library(dplyr)
ggplot() +
geom_sf(data = data_sf, aes(),
color = "#e41a1c", alpha = 0.4, size = 0.6) +
labs(
title = "Spatial Distribution of Street Light Out Reports (Chicago)",
subtitle = "Each point represents a 311 service request for streetlight outage",
caption = "Source: City of Chicago Open Data Portal"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 15, face = "bold"),
plot.subtitle = element_text(size = 12),
plot.caption = element_text(size = 9, color = "gray40"),
panel.background = element_rect(fill = "aliceblue")
)
data_proj <- st_transform(data_sf, crs = 26971)
bbox <- st_bbox(data_proj)
fishnet <- st_make_grid(
st_as_sfc(bbox),
cellsize = 500,
square = TRUE
) %>%
st_sf() %>%
mutate(grid_id = row_number())
# Visualize the fishnet grid outline
ggplot() +
geom_sf(data = fishnet, fill = NA, color = "grey40", size = 0.2) +
geom_sf(data = data_sf, color = "red", size = 0.5, alpha = 0.6) +
labs(
title = "500m Fishnet Grid over Chicago Graffiti Reports",
subtitle = "Each square represents a 500m x 500m cell",
caption = "Data source: Chicago Open Data Portal"
) +
theme_minimal()
st_crs(fishnet) <- st_crs(data_sf_proj)
st_crs(fishnet) <- st_crs(data_proj)
fishnet_counts <- st_join(fishnet, data_sf_proj, join = st_contains)
st_crs(fishnet) <- st_crs(data_proj)
fishnet_counts <- st_join(fishnet, data_proj, join = st_contains)
# Count number of graffiti incidents per grid cell
fishnet_summary <- fishnet_counts %>%
st_drop_geometry() %>%
group_by(grid_id) %>%
summarise(graffiti_count = n()) %>%
right_join(fishnet, by = "grid_id") %>%
st_as_sf()
ggplot() +
geom_sf(data = fishnet_summary, aes(fill = graffiti_count), color = "grey20") +
scale_fill_viridis_c(option = "plasma", trans = "sqrt") +
labs(
title = "500m Fishnet Grid over Chicago Graffiti Reports",
subtitle = "Graffiti points (red) aggregated within each grid cell",
fill = "Graffiti Count"
) +
theme_minimal()
library(spdep)
data_sf_grid <- fishnet_summary %>%
filter(!is.na(graffiti_count)) %>%
mutate(id = row_number())
nb <- poly2nb(data_sf_grid)
lw <- nb2listw(nb, style = "W", zero.policy = TRUE)
local_moran <- localmoran(
x = data_sf_grid$graffiti_count,
listw = lw,
zero.policy = TRUE
)
data_sf_grid <- data_sf_grid %>%
mutate(
local_I = local_moran[, 1],
local_p = local_moran[, 5],
hot_cold = case_when(
local_I > 0 & local_p < 0.05 ~ "Hot Spot",
local_I < 0 & local_p < 0.05 ~ "Cold Spot",
TRUE ~ "Not Significant"
)
)
ggplot(data_sf_grid) +
geom_sf(aes(fill = hot_cold), color = NA) +
scale_fill_manual(
values = c("Hot Spot" = "#d7191c", "Cold Spot" = "#2c7bb6", "Not Significant" = "grey80")
) +
labs(
title = "Local Moran’s I: Graffiti Removal Hot & Cold Spots",
subtitle = "City of Chicago, 2024",
fill = "Cluster Type"
) +
theme_minimal()
library(MASS)
library(broom)
data_sf_grid$neighbor_mean <- lag.listw(lw, data_sf_grid$graffiti_count, zero.policy = TRUE)
model_poisson <- glm(
graffiti_count ~ neighbor_mean + local_I,
data = data_sf_grid,
family = "poisson"
)
summary(model_poisson)
model_nb <- glm.nb(
graffiti_count ~ neighbor_mean + local_I,
data = data_sf_grid
)
aic_comparison <- data.frame(
Model = c("Poisson", "Negative Binomial"),
AIC = c(AIC(model_poisson), AIC(model_nb))
)
poisson_summary <- tidy(model_poisson)
nb_summary <- tidy(model_nb)
print(poisson_summary)
print(nb_summary)
data_sf_grid <- data_sf_grid %>%
mutate(
pred_poisson = predict(model_poisson, type = "response"),
pred_nb = predict(model_nb, type = "response")
)
ggplot(data_sf_grid, aes(x = graffiti_count, y = pred_nb)) +
geom_point(alpha = 0.4) +
geom_smooth(method = "lm", color = "blue", se = FALSE) +
labs(
title = "Observed vs Predicted (Negative Binomial Model)",
x = "Observed Graffiti Count",
y = "Predicted Count"
) +
theme_minimal()
library(Metrics)
set.seed(42)
data_sf_grid$group_id <- kmeans(st_coordinates(st_centroid(data_sf_grid)), centers = 10)$cluster
cv_results <- data.frame(group_id = character(), MAE = numeric(), RMSE = numeric())
for (g in unique(data_sf_grid$group_id)) {
train_data <- data_sf_grid[data_sf_grid$group_id != g, ]
test_data  <- data_sf_grid[data_sf_grid$group_id == g, ]
model_cv <- glm(
graffiti_count ~ neighbor_mean + local_I,
data = train_data,
family = "poisson"
)
# Predict on test data
test_data$pred <- predict(model_cv, newdata = test_data, type = "response")
# Compute errors
mae_val <- mae(test_data$graffiti_count, test_data$pred)
rmse_val <- rmse(test_data$graffiti_count, test_data$pred)
# Store results
cv_results <- rbind(cv_results, data.frame(group_id = g, MAE = mae_val, RMSE = rmse_val))
}
cv_summary <- cv_results %>%
summarise(
Mean_MAE = mean(MAE),
Mean_RMSE = mean(RMSE)
)
print(cv_summary)
ggplot(cv_results, aes(x = as.factor(group_id), y = RMSE)) +
geom_bar(stat = "identity", fill = "#3182bd") +
labs(
title = "Spatial Cross-Validation (LOGO) RMSE by Group",
x = "Spatial Group (Community Area)",
y = "RMSE"
) +
theme_minimal()
# Generate predictions and residuals
data_sf_grid <- data_sf_grid %>%
mutate(
predicted = predict(model_poisson, type = "response"),
residual = graffiti_count - predicted
)
# Map observed vs predicted counts
ggplot(data_sf_grid) +
geom_sf(aes(fill = predicted), color = NA) +
scale_fill_viridis_c(option = "magma", trans = "sqrt") +
labs(
title = "Predicted Graffiti Counts (Poisson Model)",
subtitle = "City of Chicago, 500m grid",
fill = "Predicted Count"
) +
theme_minimal()
# Map residuals (model error)
ggplot(data_sf_grid) +
geom_sf(aes(fill = residual), color = NA) +
scale_fill_gradient2(
low = "#4575b4", mid = "white", high = "#d73027",
midpoint = 0
) +
labs(
title = "Model Residuals (Observed - Predicted)",
subtitle = "Blue = under-predicted, Red = over-predicted",
fill = "Residual"
) +
theme_minimal()
install.packages("spatstat")
# KDE baseline comparison (fixed version)
library(spatstat)
library(stars)
# Transform to projected CRS (in meters, for distance-based KDE)
data_sf_proj <- st_transform(data_sf, 26971)  # NAD83 / Illinois East (meters)
# Convert to spatstat ppp object
coords <- st_coordinates(data_sf_proj)
# Create observation window from study area (fishnet extent)
win <- as.owin(st_union(st_geometry(st_transform(data_sf_grid, 26971))))
# Create ppp point pattern
graffiti_ppp <- ppp(
x = coords[, 1],
y = coords[, 2],
window = win
)
# Compute KDE
graffiti_kde <- density.ppp(graffiti_ppp, sigma = 500)  # bandwidth = 500m
# Convert to data frame for ggplot
kde_df <- as.data.frame(graffiti_kde)
colnames(kde_df) <- c("x", "y", "density")
ggplot(kde_df, aes(x, y, fill = density)) +
geom_raster() +
coord_equal() +
scale_fill_viridis_c(option = "inferno") +
labs(
title = "KDE Baseline – Graffiti Removal Density",
subtitle = "Kernel Density of 311 Graffiti Removal Reports (σ = 500m)",
fill = "Density"
) +
theme_void()
